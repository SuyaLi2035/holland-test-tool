import streamlit as st
import pandas as pd
import random
import openai
import time

# ğŸ“Œ **DeepSeek API Key**
DEEPSEEK_API_KEY = "sk-b2QUOEmlAArQ528ekQr3FzyEiI9shAJSyJW5jI4Dav8HAVzp"

# âœ… **é…ç½® OpenAI è®¿é—® DeepSeek**
openai.api_base = "https://tbnx.plus7.plus/v1"

# ================================ #
# ğŸ“Œ **è¯»å– Excel æ•°æ®**
# ================================ #
file_path = "èŒä¸šç”Ÿæ¶¯è§„åˆ’6ä¸ªä»£ç .xlsx"
xls = pd.ExcelFile(file_path)

def clean_data(df):
    """ è§£æéœå…°å¾·ä»£ç è¡¨æ ¼ï¼Œæå–ä½/ä¸­/é«˜çš„è§£è¯»æ–‡æœ¬ + æ€»ç»“ """
    parsed_data = {}
    levels = ["ä½", "ä¸­", "é«˜"]
    
    for _, row in df.iterrows():
        level = str(row.iloc[0]).strip()
        text = str(row.iloc[1]).strip()
        summary = str(row.iloc[2]).strip() if len(row) > 2 else "æš‚æ— æ€»ç»“"
        
        if level in levels and pd.notna(text):
            parsed_data[level] = {"text": text, "summary": summary}
    
    return parsed_data

holland_data = {
    "R": clean_data(pd.read_excel(xls, sheet_name='R')),
    "I": clean_data(pd.read_excel(xls, sheet_name='I')),
    "A": clean_data(pd.read_excel(xls, sheet_name='A')),
    "S": clean_data(pd.read_excel(xls, sheet_name='S')),
    "E": clean_data(pd.read_excel(xls, sheet_name='E')),
    "C": clean_data(pd.read_excel(xls, sheet_name='C')),
}

def get_holland_report(scores):
    """ ç”Ÿæˆè§£è¯»æŠ¥å‘Šï¼ˆåŒ…å«è§£è¯»æ–‡æœ¬ + æ€»ç»“ï¼‰ï¼Œå¹¶æŒ‰ç…§åˆ†å€¼ä»é«˜åˆ°ä½æ’åº """
    report = []
    summary_report = []
    
    sorted_scores = sorted(scores.items(), key=lambda x: x[1], reverse=True)

    for code, score in sorted_scores:
        level = "ä½" if score < 15 else "ä¸­" if score <= 20 else "é«˜"

        data = holland_data.get(code, {}).get(level, {"text": "æš‚æ— è§£è¯»", "summary": "æš‚æ— æ€»ç»“"})
        text = data["text"]
        summary = data["summary"]
        
        report.append(f"**{code}ï¼ˆ{level}ï¼‰**: {text}")
        summary_report.append(f"**{code} æ€»ç»“**: {summary}")

    return "\n\n".join(report), "\n\n".join(summary_report)

# ================================ #
# ğŸ“Œ **å‡½æ•°ï¼šè°ƒç”¨ DeepSeek API è¿›è¡Œ AI æ€»ç»“ï¼ˆéæµå¼ï¼‰**
# ================================ #
def summarize_report(report):
    """ ä½¿ç”¨ DeepSeek API è¿›è¡Œæ€»ç»“ """
    client = openai.OpenAI(
        base_url="https://tbnx.plus7.plus/v1",
        api_key=DEEPSEEK_API_KEY
    )

    try:
        response = client.chat.completions.create(
            model="deepseek-chat",
            messages=[
                {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªå›½é™…èŒä¸šç”Ÿæ¶¯è§„åˆ’å¸ˆï¼Œè¯·ç”Ÿæˆä¸€æ®µæ¸…æ™°ã€ç²¾å‡†çš„æ€»ç»“ï¼Œæ€»ç»“æ§åˆ¶åœ¨200-300å­—åŒºé—´ï¼Œç”¨â€˜ä½ â€™æè¿°ï¼Œä¸è¦ä½¿ç”¨è¯¥ç”¨æˆ·ï¼Œç»“å°¾ç»™å‡º1-2å¥ç®€çŸ­çš„å»ºè®®ï¼Œè¯­è¨€è¦æ¸©å’Œï¼Œå®¢æˆ·å¬äº†ä¼šå¾ˆèˆ’æœï¼Œä¸éœ€è¦å¼ºè°ƒèŒä¸šæ–¹å‘ï¼Œåªéœ€è¦æè¿°å®¢æˆ·æ˜¯ä¸€ä¸ªä»€ä¹ˆæ ·çš„äººã€‚"},
                {"role": "user", "content": f"è¯·æ€»ç»“ä»¥ä¸‹éœå…°å¾·æµ‹è¯•æŠ¥å‘Šå†…å®¹ï¼š\n\n{report}"}
            ]
        )
        return response.choices[0].message.content
    except Exception as e:
        return f"âŒ æ€»ç»“å¤±è´¥ï¼š{str(e)}"

# ================================ #
# ğŸ“Œ **å‡½æ•°ï¼šè°ƒç”¨ DeepSeek API è¿›è¡Œå¼‚è®®è§£ç­”ï¼ˆæµå¼è¾“å‡ºï¼‰**
# ================================ #
def answer_objection(question):
    """ ä½¿ç”¨ DeepSeek API è¿›è¡Œå¼‚è®®è§£ç­”ï¼Œå¹¶è°ƒç”¨çŸ¥è¯†åº“ """
    client = openai.OpenAI(
        base_url="https://tbnx.plus7.plus/v1",
        api_key=DEEPSEEK_API_KEY
    )

    # **æ„é€  AI æŒ‡ä»¤**
    system_prompt = (
        "è¯·ä½ ä½œä¸ºä¸€ä¸ªæ²Ÿé€šé«˜æ‰‹ï¼Œæ‡‚äººæ€§ã€æ‡‚å¿ƒç†å­¦ï¼Œä¼šè®²äººè¯ï¼Œå¾ˆä¼šåˆ©ç”¨æŸå¤±åŒæ¶ã€æ²‰æ²¡æˆæœ¬ç­‰æ³•åˆ™ã€‚\n\n"
        "è¯·ä½¿ç”¨ä»¥ä¸‹æ¡†æ¶å›ç­”é—®é¢˜ï¼šPraise-èµç¾ã€‘ï¼šæ¥çº³å¹¶ç†è§£ä½ çš„æƒ…ç»ªå’Œæ„Ÿå—ï¼Œæ˜ç¡®è¯†åˆ«å‡ºä½ å†…å¿ƒçš„éœ€æ±‚ï¼Œã€Feature-äº§å“ç‰¹å¾ã€‘ï¼šæ˜ç¡®å®šä¹‰é—®é¢˜ã€æ‹†åˆ†åˆ†ç±»ï¼ˆè¡¨é¢ç°è±¡vsæ·±å±‚åŸå› ã€è¡Œä¸ºè¡¨ç°vså†…å¿ƒéœ€æ±‚ã€æƒ…ç»ªæ„Ÿå—vsäº‹å®çœŸç›¸ï¼‰ï¼Œä½“ç°è¿™ç§æ²Ÿé€šæ–¹å¼çš„ç‰¹å¾ï¼Œã€Advantage-äº§å“ä¼˜åŠ¿ã€‘ï¼šè¯´æ˜ç²¾å‡†å®šä¹‰å’Œåˆ†ç±»åï¼Œèƒ½å¸¦æ¥çš„ç›´æ¥ä¼˜åŠ¿ï¼ˆæ¯”å¦‚æ‘†è„±æƒ…ç»ªå›°æ‰°ã€ç†æ¸…çœŸæ­£é—®é¢˜ï¼‰ï¼Œã€Benefit-å¥½å¤„ã€‘æä¾›é•¿æœŸä¸»ä¹‰æˆ–æ•™è‚²å‡æ³•çš„æ–°è§†è§’ï¼Œå»ºç«‹ç§¯ææˆ–å®¢è§‚çš„è®¤çŸ¥ï¼Œæå‡æ²Ÿé€šæ•ˆç‡å’Œæ•ˆæœï¼Œã€Close-ç»“å°¾å…³å•ã€‘æœ€åé€šè¿‡å»ºè®®æˆ–å‘èµ·è¡ŒåŠ¨ï¼Œå¼•å¯¼ä½ å»å®é™…åº”ç”¨å’Œå®è·µã€‚åœ¨ä½¿ç”¨ä»¥ä¸Šæ¡†æ¶å›ç­”é—®é¢˜çš„æ—¶å€™ï¼Œç¡®ä¿äº§å‡ºçš„å†…å®¹ï¼Œè¯´äººè¯ï¼Œæ¡†æ¶äºæ¡†æ¶ä¹‹é—´è¿è´¯ï¼Œä¸”æ²Ÿé€šçš„è§†è§’æ˜¯æˆ‘å‘å®¢æˆ·è¯´çš„è§†è§’ï¼Œå»ºç«‹1-2æ¬¡äº’åŠ¨ï¼Œå®¢æˆ·å¬æ„Ÿèˆ’æœã€‚ã€‚\n"
        "åŒæ—¶ï¼Œä½ å¯ä»¥å‚è€ƒä»¥ä¸‹çŸ¥è¯†åº“ä¸­çš„ä¿¡æ¯ï¼Œç»“åˆä¿¡æ¯åº“æŒ‰ç…§æ¡†æ¶ï¼Œä»¥ç¡®ä¿å›ç­”å‡†ç¡®ä¸”æœ‰è¯´æœåŠ›ã€‚\n"
        "å¦‚æœçŸ¥è¯†åº“ä¸­æœ‰ç›¸å…³å†…å®¹ï¼Œè¯·ä¼˜å…ˆä½¿ç”¨ï¼›å¦‚æœæ²¡æœ‰ï¼Œåˆ™è‡ªç”±å‘æŒ¥ï¼Œä½†ä¸€å®šæ˜¯å’Œæ•™è‚²ã€é•¿æœŸä¸»ä¹‰ç›¸å…³ã€‚\n\n"

    )

    try:
        response = client.chat.completions.create(
            model="deepseek-chat",
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": f"ç”¨æˆ·çš„é—®é¢˜ï¼š{question}"}
            ],
            stream=True  # âœ… å¯ç”¨æµå¼è¾“å‡º
        )

        response_text = ""
        response_container = st.empty()

        for chunk in response:
            if chunk.choices and chunk.choices[0].delta and chunk.choices[0].delta.content:
                text = chunk.choices[0].delta.content.strip()
                if text:
                    response_text += text + "\n\n"  # **ç¡®ä¿æ¢è¡Œ**
                    response_container.markdown(response_text)  # **å®æ—¶æ›´æ–° UI**
                    yield text  # âœ… é€æ­¥è¿”å›å†…å®¹

    except Exception as e:
        st.error(f"âŒ è§£ç­”å¤±è´¥ï¼š{str(e)}")
        yield f"âŒ è§£ç­”å¤±è´¥ï¼š{str(e)}"


# ğŸ“Œ **å‡½æ•°ï¼šåŠ è½½çŸ¥è¯†åº“**
import os
from PyPDF2 import PdfReader
import docx

def load_knowledge_base():
    """ è¯»å– knowledge_base ç›®å½•ä¸‹çš„æ‰€æœ‰ Word å’Œ PDF æ–‡ä»¶ï¼Œå¹¶åˆå¹¶å†…å®¹ """
    knowledge_base_text = ""

    if not os.path.exists("knowledge_base"):
        os.makedirs("knowledge_base")  # **å¦‚æœç›®å½•ä¸å­˜åœ¨ï¼Œåˆ›å»ºå®ƒ**

    for file in os.listdir("knowledge_base"):
        file_path = os.path.join("knowledge_base", file)

        if file.endswith(".pdf"):
            try:
                reader = PdfReader(file_path)
                for page in reader.pages:
                    knowledge_base_text += page.extract_text() + "\n"
            except Exception as e:
                print(f"âŒ è¯»å– PDF å¤±è´¥ï¼š{file_path}ï¼Œé”™è¯¯ï¼š{str(e)}")

        elif file.endswith(".docx"):
            try:
                doc = docx.Document(file_path)
                for para in doc.paragraphs:
                    knowledge_base_text += para.text + "\n"
            except Exception as e:
                print(f"âŒ è¯»å– Word å¤±è´¥ï¼š{file_path}ï¼Œé”™è¯¯ï¼š{str(e)}")

    if not knowledge_base_text.strip():
        print("âš ï¸ çŸ¥è¯†åº“ä¸ºç©ºï¼ŒAI å°†è‡ªè¡Œå›ç­”ã€‚")
    
    return knowledge_base_text

# âœ… **åŠ è½½çŸ¥è¯†åº“**
knowledge_base_content = load_knowledge_base()



# ================================ #
# ğŸ“Œ **å‡½æ•°ï¼šè°ƒç”¨ AI è¿›è¡Œå¼‚è®®è§£ç­”**
# ================================ #
def answer_objection(question):
    """ ä½¿ç”¨ DeepSeek API è¿›è¡Œå¼‚è®®è§£ç­”ï¼Œå¹¶è°ƒç”¨çŸ¥è¯†åº“ """
    client = openai.OpenAI(
        base_url="https://tbnx.plus7.plus/v1",
        api_key=DEEPSEEK_API_KEY
    )

    # **ç¡®ä¿çŸ¥è¯†åº“å†…å®¹è¢«æ­£ç¡®ä¼ é€’**
    if knowledge_base_content.strip():
        system_prompt = (
            "ä½ æ˜¯ä¸€ä¸ªè¥é”€æ²Ÿé€šé«˜æ‰‹ï¼Œæ‡‚äººæ€§ã€æ‡‚å¿ƒç†å­¦ï¼Œå¾ˆä¼šåˆ©ç”¨æŸå¤±åŒæ¶ã€æ²‰æ²¡æˆæœ¬ç­‰æ³•åˆ™ï¼Œä¿ƒä½¿å®¢æˆ·æˆäº¤ã€‚\n\n"
            "è¯·ä½¿ç”¨â€˜Praise-èµç¾ / Feature-äº§å“ç‰¹å¾ / Advantage-äº§å“ä¼˜åŠ¿ / Benefit-å¯¹ä½ çš„æ”¶ç›Š / Close-ç»“å°¾å…³å•â€™æ¡†æ¶å›ç­”ç”¨æˆ·é—®é¢˜ã€‚\n"
            "è¯·ä¼˜å…ˆå‚è€ƒä»¥ä¸‹çŸ¥è¯†åº“å†…å®¹ï¼Œä»¥ç¡®ä¿å›ç­”å‡†ç¡®ä¸”æœ‰è¯´æœåŠ›ï¼š\n\n"
            f"ğŸ“š çŸ¥è¯†åº“å†…å®¹ï¼ˆéƒ¨åˆ†ï¼‰ï¼š\n{knowledge_base_content[:2000]}\n\n"  # **æˆªå–å‰ 2000 å­—**
            "å¦‚æœçŸ¥è¯†åº“ä¸­æ²¡æœ‰ç›¸å…³å†…å®¹ï¼Œå¯ä»¥è‡ªç”±å‘æŒ¥ï¼Œä½†ä»ç„¶éµå¾ªä¸Šè¿°ç»“æ„è¿›è¡Œå›ç­”ã€‚\n"
        )
    else:
        system_prompt = (
            "ä½ æ˜¯ä¸€ä¸ªè¥é”€æ²Ÿé€šé«˜æ‰‹ï¼Œæ‡‚äººæ€§ã€æ‡‚å¿ƒç†å­¦ï¼Œå¾ˆä¼šåˆ©ç”¨æŸå¤±åŒæ¶ã€æ²‰æ²¡æˆæœ¬ç­‰æ³•åˆ™ï¼Œä¿ƒä½¿å®¢æˆ·æˆäº¤ã€‚\n\n"
            "è¯·ä½¿ç”¨â€˜Praise-èµç¾ / Feature-äº§å“ç‰¹å¾ / Advantage-äº§å“ä¼˜åŠ¿ / Benefit-å¯¹ä½ çš„æ”¶ç›Š / Close-ç»“å°¾å…³å•â€™æ¡†æ¶å›ç­”ç”¨æˆ·é—®é¢˜ã€‚\n"
            "âš ï¸ çŸ¥è¯†åº“ä¸ºç©ºï¼Œä½ éœ€è¦è‡ªè¡Œæ¨ç†å¹¶å›ç­”ã€‚\n"
        )

    try:
        response = client.chat.completions.create(
            model="deepseek-chat",
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": f"ç”¨æˆ·çš„é—®é¢˜ï¼š{question}"}
            ],
            stream=True  # âœ… å¯ç”¨æµå¼è¾“å‡º
        )

        response_text = ""  # ç”¨äºå­˜å‚¨å®Œæ•´å›ç­”
        buffer = ""  # ä¸´æ—¶å­˜å‚¨å•å¥
        response_container = st.empty()

        for chunk in response:
            if chunk.choices and chunk.choices[0].delta and chunk.choices[0].delta.content:
                text = chunk.choices[0].delta.content.strip()

                if text:
                    buffer += text

                    # **æ£€æµ‹å¥å·ã€é—®å·ã€æ„Ÿå¹å·ï¼Œåˆ¤æ–­æ˜¯å¦å®Œæ•´å¥å­**
                    if any(end in buffer for end in ["ã€‚", "ï¼", "ï¼Ÿ"]):
                        response_text += buffer + "\n\n"  # **æ·»åŠ æ¢è¡Œï¼Œç¡®ä¿åˆ†è¡Œæ˜¾ç¤º**
                        buffer = ""  # **æ¸…ç©ºä¸´æ—¶å­˜å‚¨ï¼Œå‡†å¤‡å­˜ä¸‹ä¸€å¥**
                        response_container.markdown(response_text)  # **æ›´æ–° UI**

        # **ç¡®ä¿æœ€åçš„å†…å®¹ä¹Ÿè¢«æ¸²æŸ“**
        if buffer:
            response_text += buffer + "\n\n"
            response_container.markdown(response_text)

    except Exception as e:
        st.error(f"âŒ è§£ç­”å¤±è´¥ï¼š{str(e)}")
        yield f"âŒ è§£ç­”å¤±è´¥ï¼š{str(e)}"




st.markdown("<h1 style='text-align: center; color: #FF4B4B; font-weight: bold;'>éœå…°å¾·èŒä¸šå…´è¶£æµ‹è¯•</h1>", unsafe_allow_html=True)


# ================================ #
# ğŸ“Œ **å¼‚è®®è§£ç­”æ¨¡å—ï¼ˆæµå¼è¾“å‡º + çŸ¥è¯†åº“æ”¯æŒï¼‰**
# ================================ #
with st.sidebar:
    st.markdown("## ğŸ¤– **å¼‚è®®è§£ç­”**")
    user_question = st.text_input("ğŸ” è¯·è¾“å…¥ä½ çš„é—®é¢˜ï¼š", key="objection_input_1")
    
    if st.button("ğŸš€ æäº¤å¹¶è§£ç­”", key="objection_submit_1"):
        if user_question.strip():
            with st.spinner("ğŸ¤– AI æ­£åœ¨æŸ¥è¯¢ï¼Œè¯·ç¨å€™..."):
                response_text = ""
                response_container = st.empty()

                for partial_response in answer_objection(user_question):
                    response_text += partial_response + "\n\n"  # âœ… é€æ­¥æ‹¼æ¥ï¼Œå¼ºåˆ¶æ¢è¡Œ
                    response_container.markdown(response_text)




# ================================ #
# ğŸ“Œ **ä»£ç è§£è¯»è¾“å…¥æ¡†**
# ================================ #
col1, col2, col3 = st.columns(3)

with col1:
    r = st.number_input("ğŸ”§ Rï¼ˆå®é™…å‹ï¼‰", min_value=0, max_value=40, value=20, step=1)
    i = st.number_input("ğŸ”¬ Iï¼ˆç ”ç©¶å‹ï¼‰", min_value=0, max_value=40, value=20, step=1)

with col2:
    a = st.number_input("ğŸ¨ Aï¼ˆè‰ºæœ¯å‹ï¼‰", min_value=0, max_value=40, value=20, step=1)
    s = st.number_input("ğŸ¤ Sï¼ˆç¤¾ä¼šå‹ï¼‰", min_value=0, max_value=40, value=20, step=1)

with col3:
    e = st.number_input("ğŸ’¼ Eï¼ˆä¼ä¸šå‹ï¼‰", min_value=0, max_value=40, value=20, step=1)
    c = st.number_input("ğŸ“Š Cï¼ˆå¸¸è§„å‹ï¼‰", min_value=0, max_value=40, value=20, step=1)

st.markdown("---")

# ================================ #
# ğŸ“Œ **æäº¤æŒ‰é’®**
# ================================ #
if st.button("ğŸ“Œ **æäº¤å¹¶æŸ¥çœ‹è§£è¯»**", key="report_submit"):
    scores = {"R": r, "I": i, "A": a, "S": s, "E": e, "C": c}
    report, summary = get_holland_report(scores)

    st.markdown("## ğŸ“Œ **ä½ çš„è§£è¯»æŠ¥å‘Š**")
    st.markdown(report)

    with st.spinner("ğŸ¤– AI æ­£åœ¨æ€»ç»“ä½ çš„æŠ¥å‘Šï¼Œè¯·ç¨å€™..."):
        ai_summary = summarize_report(report)

    st.markdown("## ğŸ¤– **AI ç”Ÿæˆæ€»ç»“**")
    st.markdown(ai_summary)
